{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = {\"can_start\": False,\n",
    "         \"dataset\" : False,\n",
    "         \"model\": False,\n",
    "         \"profile\": False,\n",
    "         \"profile_waiting\": False,\n",
    "         \"intent\": \"null\",\n",
    "         \"entities\": {\"record\": \"null\",\n",
    "                      \"label\": \"null\",\n",
    "                      \"act_label\": \"null\",\n",
    "                      \"des_label\": \"null\",\n",
    "                      \"feature\": \"null\",\n",
    "                      \"new_val\": \"null\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(inp):\n",
    "    global brain\n",
    "    if brain[\"can_start\"]:\n",
    "        model = brain[\"model\"]\n",
    "        dataset = brain[\"dataset\"]\n",
    "        print(f'Great! so we are going to talk about {dataset} dataset and {model} model.')\n",
    "        # pass inp to RespoAlgo\n",
    "    else:\n",
    "        # can't start yet\n",
    "        if brain[\"dataset\"]:\n",
    "            # dataset is in brain\n",
    "            if brain[\"model\"]:\n",
    "                # model is in brain\n",
    "                if brain[\"profile\"]:\n",
    "                    brain[\"can_start\"] = True\n",
    "                esle:\n",
    "                    if brain[\"profile_waiting\"]:\n",
    "                        brain[\"profile\"] = inp\n",
    "                        brain[\"profile_waiting\"] = False\n",
    "                    else:\n",
    "                        print('What is your profile ?')\n",
    "                        brain[\"profile_waiting\"] = True\n",
    "            # model NOT in brain\n",
    "            else:\n",
    "                if brain[\"model_waiting\"]:\n",
    "                        brain[\"model\"] = inp\n",
    "                        brain[\"model_waiting\"] = False\n",
    "                    else:\n",
    "                        print('What is your model ?')\n",
    "                        brain[\"model_waiting\"] = True\n",
    "        else:\n",
    "            # no dataset in brain\n",
    "            if brain[\"dataset_waiting\"]:\n",
    "                brain[\"dataset\"] = inp\n",
    "                brain[\"dataset_waiting\"] = False\n",
    "            else:\n",
    "                print('What is the dataset ?')\n",
    "                brain[\"dataset_waiting\"] = True\n",
    "            \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(user_input):\n",
    "    \"\"\"\n",
    "    The main function which gets the initial values (datset, model and profile)\n",
    "    from user and when everything is ready passes the input to the RespoAlgo\n",
    "    \"\"\"\n",
    "    global memory\n",
    "    memory = load_brain()\n",
    "\n",
    "    missing, filling, mind_change, can_start, _dataset_waiting, _model_waiting, _profile_waiting = load_memory_files()\n",
    "    if can_start:\n",
    "        # pass inp to RespoAlgo\n",
    "        main(user_input)\n",
    "    else:\n",
    "        if memory[\"dataset\"] is not None:\n",
    "            # dataset is in memory\n",
    "            if memory[\"model\"] is not None:\n",
    "                # model is in memory\n",
    "                if memory[\"profile\"] is not None:\n",
    "                    memory[\"can_start\"] = True\n",
    "                else:\n",
    "                    if _profile_waiting:\n",
    "                        memory[\"profile\"] = user_input\n",
    "                        with open('_profile_waiting.p', 'wb') as file:\n",
    "                            pickle.dump(False, file)\n",
    "                    else:\n",
    "                        with open('_profile_waiting.p', 'wb') as file:\n",
    "                            pickle.dump(True, file)\n",
    "                        return {\n",
    "                            \"msg\": \"Which profile does describe you better?\",\n",
    "                            \"options\": ['User', 'Developer', 'Manager'],\n",
    "                            \"intention\": \"wants_list\",\n",
    "                            \"end_of_converstaion\": False,\n",
    "                        }\n",
    "\n",
    "            # model NOT in memory\n",
    "            else:\n",
    "                if _model_waiting:\n",
    "                    memory[\"model\"] = user_input\n",
    "                    with open('_model_waiting.p', 'wb') as file:\n",
    "                        pickle.dump(False, file)\n",
    "                else:\n",
    "                    with open('_model_waiting.p', 'wb') as file:\n",
    "                        pickle.dump(True, file)\n",
    "                    return {\n",
    "                        \"msg\": \"Which is the model you want to use?\",\n",
    "                        \"options\": ['Logistic Regression', 'XGBoost'],\n",
    "                        \"intention\": \"wants_list\",\n",
    "                        \"end_of_converstaion\": False,\n",
    "                    }\n",
    "\n",
    "        else:\n",
    "            # no dataset in memory\n",
    "            if _dataset_waiting:\n",
    "                memory[\"dataset\"] = user_input\n",
    "                with open('_dataset_waiting.p', 'wb') as file:\n",
    "                    pickle.dump(False, file)\n",
    "            else:\n",
    "\n",
    "                with open('_dataset_waiting.p', 'wb') as file:\n",
    "                    pickle.dump(True, file)\n",
    "                return {\n",
    "                    \"msg\": \"Which is the dataset you need explanations for?\",\n",
    "                    \"options\": ['IRIS', '20NewsGroup'],\n",
    "                    \"intention\": \"wants_list\",\n",
    "                    \"end_of_converstaion\": False,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/navid/Documents/rasa_practice/XAIBot_V1/navid-flask-chat-app/flask-server/brain.json', 'r') as file:\n",
    "    brain = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(user_input):\n",
    "    \"\"\"\n",
    "    The main function which gets the initial values (datset, model and profile)\n",
    "    from user and when everything is ready passes the input to the RespoAlgo\n",
    "    \"\"\"\n",
    "    def update_element(element, value):\n",
    "        with open(f'{element}.p', 'wb') as file:\n",
    "            pickle.dump(value, file)\n",
    "        \n",
    "    \n",
    "    global memory\n",
    "    memory = load_brain()\n",
    "\n",
    "    missing, filling, mind_change, can_start, _dataset_waiting, _model_waiting, _profile_waiting = load_memory_files()\n",
    "    if can_start:\n",
    "        # pass inp to RespoAlgo\n",
    "        main(user_input)\n",
    "    else:\n",
    "        if memory[\"dataset\"]:\n",
    "            # dataset is in memory\n",
    "            if memory[\"model\"]:\n",
    "                # model is in memory\n",
    "                memory[\"profile\"] = user_input\n",
    "                update_element('_profile_waiting', False)\n",
    "                update_element('can_start', True)\n",
    "                \n",
    "                model = memory[\"model\"]\n",
    "                dataset = memory[\"dataset\"]\n",
    "                return {\n",
    "                \"msg\": f'Great! so we are going to talk about {dataset} dataset and {model} model.',\n",
    "                \"intention\": \"wants_answer\",\n",
    "                \"end_of_converstaion\": False,\n",
    "                        }\n",
    "            else:\n",
    "                update_element('_model_waiting', False)\n",
    "                memory[\"model\"] = user_input\n",
    "                update_element('_profile_waiting', True)\n",
    "                return {\n",
    "                            \"msg\": \"Which profile does describe you better?\",\n",
    "                            \"options\": ['User', 'Developer', 'Manager'],\n",
    "                            \"intention\": \"wants_list\",\n",
    "                            \"end_of_converstaion\": False,\n",
    "                        }\n",
    "                \n",
    "                \n",
    "        # no dataset            \n",
    "        else:\n",
    "            if _dataset_waiting:\n",
    "                memory[\"dataset\"] = user_input\n",
    "                update_element('_dataset_waiting', False)\n",
    "                update_element('_model_waiting', True)\n",
    "                return {\n",
    "                        \"msg\": \"Which is the model you want to use?\",\n",
    "                        \"options\": ['Logistic Regression', 'XGBoost'],\n",
    "                        \"intention\": \"wants_list\",\n",
    "                        \"end_of_converstaion\": False,\n",
    "                    }\n",
    "            else:\n",
    "                update_element('_dataset_waiting', True)\n",
    "                return {\n",
    "                    \"msg\": \"Which is the dataset you need explanations for?\",\n",
    "                    \"options\": ['IRIS', '20NewsGroup'],\n",
    "                    \"intention\": \"wants_list\",\n",
    "                    \"end_of_converstaion\": False,\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': None,\n",
       " 'model': None,\n",
       " 'intent': None,\n",
       " 'entities': {'record': None,\n",
       "  'label': None,\n",
       "  'act_label': None,\n",
       "  'des_label': None,\n",
       "  'feature': None,\n",
       "  'new_val': None}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brain[\"dataset\"]:\n",
    "    print('sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
